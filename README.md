ğŸ“‹ Project Overview
This project presents a novel CBAM-guided channel pruning framework for efficient osteoporosis classification using knee X-ray images. The methodology achieves 55.9% parameter reduction while maintaining 93.8% diagnostic accuracy, enabling deployment in resource-constrained clinical environments.
ğŸ¯ Key Achievements

âœ… 55.9% parameter reduction with only 0.4% accuracy loss
âœ… 38.9% FLOPs reduction and 35% inference speedup
âœ… 93.8% classification accuracy on osteoporosis dataset
âœ… Validated across 7 CNN architectures (ResNet-18, VGG16, MobileNetV2, EfficientNet-B0, DenseNet-121, SqueezeNet, ShuffleNetV2)
âœ… Outperforms existing pruning methods (L1 norm, iterative magnitude, SE attention)


ğŸ”¬ Research Highlights
Problem Statement
Deep learning models excel at medical image classification but their computational complexity prevents deployment in resource-limited clinical settings. Existing pruning methods either achieve minimal compression (<5%) or suffer catastrophic accuracy loss (>40%).
Our Solution
CBAM-Guided Intelligent Pruning that:

Uses dual attention mechanisms (channel + spatial) to identify diagnostically critical features
Systematically removes redundant parameters while preserving medical relevance
Implements progressive layer-wise pruning strategy (20-60% across network depth)
Achieves optimal compression-accuracy trade-off

Clinical Impact
Enables deployment of sophisticated osteoporosis detection models on:

ğŸ“± Mobile devices
ğŸ’» Edge devices
ğŸ¥ Resource-constrained clinics
ğŸŒ Rural healthcare facilities


ğŸ—ï¸ Architecture Overview
Input X-ray Image (224Ã—224)
         â†“
    Preprocessing
    (Normalization + Augmentation)
         â†“
    AttentionResNet18
    (CBAM-enhanced)
         â†“
    CBAM Attention Module
    â”œâ”€ Channel Attention
    â”‚  (identifies important features)
    â””â”€ Spatial Attention
       (focuses on anatomical regions)
         â†“
    Attention-Guided Pruning
    (removes redundant channels)
         â†“
    Pruned Model
    (55.9% smaller, 35% faster)
         â†“
    Classification Output
    [Healthy | Osteopenia | Osteoporosis]

ğŸ“Š Dataset
Osteoporosis X-ray Dataset

Total Images: 6,750 knee X-rays
Resolution: 224Ã—224 pixels
Classes: 3 (multiclass classification)

Healthy: 2,890 images
Osteopenia: 1,436 images
Osteoporosis: 2,424 images


Split: 60% train / 20% validation / 20% test

Data Preprocessing

âœ… Z-score normalization
âœ… Balanced sampling strategy
âœ… Data augmentation:

Spatial: Horizontal flip, rotation (Â±10Â°), affine transforms
Photometric: Brightness/contrast adjustment (Â±20%)
Advanced: MixUp augmentation (Î±=0.2)




ğŸ› ï¸ Technical Details
Model Architecture
Base Model: ResNet-18 with CBAM attention

Original Parameters: 11.7M â†’ Pruned: 4.8M (59% reduction)
Original FLOPs: 3.42B â†’ Pruned: 2.09B (39% reduction)
Original Inference: 12.4ms â†’ Pruned: 8.7ms (30% faster)

CBAM Attention Mechanism
Channel Attention:
M_c(F) = Ïƒ(MLP(AvgPool(F)) + MLP(MaxPool(F)))
Spatial Attention:
M_s(F') = Ïƒ(Conv_7Ã—7([AvgPool(F'); MaxPool(F')]))
Combined Output:
F' = M_c(F) âŠ— F
F'' = M_s(F') âŠ— F'
Pruning Algorithm
Channel Importance Calculation:
Importance(c_i) = (1/N) * Î£ Attention(c_i, x_j)
Progressive Pruning Strategy:

Layer 1: 0-31% pruning (preserve early features)
Layer 2: 30-45% pruning
Layer 3: 45-55% pruning
Layer 4: 50-60% pruning (aggressive on deep layers)


ğŸš€ Installation & Setup
Prerequisites
bashPython >= 3.8
PyTorch >= 1.10.0
CUDA >= 11.0 (for GPU support)
Required Libraries
bashpip install torch torchvision
pip install numpy pandas matplotlib
pip install scikit-learn opencv-python
pip install tensorboard
pip install timm  # For model architectures
Clone Repository
bashgit clone https://github.com/yourusername/osteoporosis-pruning.git
cd osteoporosis-pruning
Install Dependencies
bashpip install -r requirements.txt
```

---

## ğŸ“ Project Structure
```
osteoporosis-pruning/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original X-ray images
â”‚   â”œâ”€â”€ processed/              # Preprocessed images
â”‚   â””â”€â”€ splits/                 # Train/val/test splits
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ attention_resnet18.py   # AttentionResNet18 architecture
â”‚   â”œâ”€â”€ cbam.py                 # CBAM attention module
â”‚   â””â”€â”€ pruned_models/          # Saved pruned models
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing pipeline
â”‚   â”œâ”€â”€ training.py             # Model training script
â”‚   â”œâ”€â”€ pruning.py              # Attention-guided pruning
â”‚   â”œâ”€â”€ evaluation.py           # Model evaluation metrics
â”‚   â””â”€â”€ utils.py                # Utility functions
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â”œâ”€â”€ 03_pruning_analysis.ipynb
â”‚   â””â”€â”€ 04_results_visualization.ipynb
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train_config.yaml       # Training hyperparameters
â”‚   â””â”€â”€ prune_config.yaml       # Pruning configurations
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # Generated visualizations
â”‚   â”œâ”€â”€ models/                 # Trained model checkpoints
â”‚   â””â”€â”€ metrics/                # Performance metrics
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ LICENSE                     # License information

ğŸ’» Usage
1. Data Preparation
pythonfrom src.preprocessing import prepare_dataset

# Prepare and split dataset
prepare_dataset(
    data_path='data/raw/',
    output_path='data/processed/',
    train_ratio=0.6,
    val_ratio=0.2,
    test_ratio=0.2
)
2. Train Base Model
pythonfrom src.training import train_model

# Train AttentionResNet18
model = train_model(
    model_name='attention_resnet18',
    data_path='data/processed/',
    epochs=15,
    batch_size=32,
    learning_rate=0.001,
    save_path='results/models/base_model.pth'
)
3. Apply CBAM-Guided Pruning
pythonfrom src.pruning import apply_attention_pruning

# Prune model using CBAM attention
pruned_model = apply_attention_pruning(
    model=model,
    pruning_rate=0.559,  # 55.9% parameter reduction
    importance_threshold=0.3,
    save_path='results/models/pruned_model.pth'
)
4. Evaluate Pruned Model
pythonfrom src.evaluation import evaluate_model

# Evaluate on test set
results = evaluate_model(
    model=pruned_model,
    test_loader=test_loader,
    metrics=['accuracy', 'precision', 'recall', 'f1', 'auc']
)

print(f"Accuracy: {results['accuracy']:.2%}")
print(f"F1-Score: {results['f1']:.2%}")
5. Compare Efficiency
pythonfrom src.evaluation import compare_efficiency

# Compare original vs pruned
comparison = compare_efficiency(
    original_model=model,
    pruned_model=pruned_model,
    input_size=(1, 3, 224, 224)
)

print(f"Parameter Reduction: {comparison['param_reduction']:.1%}")
print(f"FLOP Reduction: {comparison['flop_reduction']:.1%}")
print(f"Inference Speedup: {comparison['speedup']:.1%}")

ğŸ“ˆ Results
Model Performance
MetricOriginal ModelPruned ModelChangeAccuracy94.2%93.8%-0.4%Precision94.8%94.3%-0.5%Recall95.1%94.7%-0.4%F1-Score94.9%94.5%-0.4%
Efficiency Gains
MetricOriginalPrunedReductionParameters11.7M4.8M55.9% â†“FLOPs3.42B2.09B38.9% â†“Model Size47.2 MB19.4 MB58.9% â†“Inference Time12.4 ms8.7 ms29.8% â†“GPU Memory892 MB524 MB41.3% â†“
Cross-Architecture Results
ArchitectureParam ReductionAccuracyF1-ScoreSpeedupResNet-1855.9%94.8%95.0%38.1%VGG1650.0%93.8%92.0%39.0%MobileNetV248.2%93.5%93.8%42.3%EfficientNet-B052.7%94.2%94.5%41.8%DenseNet-12149.8%93.9%94.1%40.5%Average50.9%93.7%93.7%41.3%
Comparison with State-of-the-Art
MethodParam ReductionAccuracySpeedupCBAM (Ours)55.9%94.8%38.1%L1 Norm Pruning2.99%83.2%1.2%Iterative Magnitude4.3%54.3%2.4%SE Attention3.93%50.9%2.4%Automatic Attention0.08%89.1%0%
